# AuroraNet  
AuroraNet est un modèle de deep learning qui génère des coordonnées faciales à partir d'entrées audio, en utilisant des spectrogrammes comme base d'entraînement. Cette version initiale valide l'idée en s'appuyant sur le dataset **VocazSet**.

## Fonctionnalités  
- Conversion de spectrogrammes audio en coordonnées faciales.  
- Première étape vers la synchronisation audio-visuelle pour des applications interactives.  

## Technologies utilisées  
- **Python** : Langage principal du projet.  
- **TensorFlow** : Frameworks de deep learning.  
- **Librosa** : Extraction de caractéristiques audio et spectrogrammes.  
- **Seaborn** : Visualisation des données.


## Étapes futures  
Une fois l'idée validée, l'objectif est de développer un dataset personnalisé. Ce dataset permettra non seulement de reconnaître les expressions faciales avec une plus grande précision, mais aussi d'intégrer la détection des mouvements de tête pour des interactions plus dynamiques et réalistes.  

Avec cette avancée, AuroraNet pourra être utilisé dans des domaines variés comme :  
- Les jeux vidéo et les mondes virtuels interactifs.  
- Les avatars animés pour les applications de visioconférence.  
- L'amélioration de la synchronisation labiale dans les films ou animations.
