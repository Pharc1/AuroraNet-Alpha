# AuroraNet ğŸš€  
AuroraNet est un modÃ¨le de deep learning conÃ§u pour gÃ©nÃ©rer des **coordonnÃ©es faciales** Ã  partir d'entrÃ©es audio, en transformant des spectrogrammes en animations faciales rÃ©alistes.  
ğŸŒŸ Cette premiÃ¨re version s'appuie sur le dataset public **VocaSet** pour valider le concept.  

---

## ğŸŒŸ FonctionnalitÃ©s principales  
- ğŸ™ï¸ **Conversion audio -> expressions faciales** : Synchronisation visuelle basÃ©e sur des spectrogrammes audio.  
- ğŸ› ï¸ **PremiÃ¨re Ã©tape** vers une interaction audio-visuelle immersive.  

---

## ğŸ”§ Technologies utilisÃ©es  
- ğŸ **Python** : Langage principal.  
- ğŸ”¬ **TensorFlow** : Framework de deep learning pour l'entraÃ®nement du modÃ¨le.  
- ğŸµ **Librosa** : Analyse audio et gÃ©nÃ©ration de spectrogrammes.  
- ğŸ“Š **Seaborn** : Visualisation des rÃ©sultats pour analyse des performances.  

---

## ğŸš€ Ã‰tapes futures  
ğŸ¯ Une fois l'idÃ©e validÃ©e avec **VocaSet**, l'objectif est de **passer Ã  un dataset personnalisÃ©**. Ce dataset permettra :  
- ğŸ¤© **ReconnaÃ®tre les expressions faciales** avec une meilleure prÃ©cision.  
- ğŸ¤– **DÃ©tecter les mouvements de tÃªte** pour une interaction encore plus naturelle et dynamique.  

ğŸ” **Applications possibles** :  
- ğŸ® **Jeux vidÃ©o et mondes virtuels** : Synchronisation labiale et expressions rÃ©alistes pour des avatars.  
- ğŸ¥ **CinÃ©ma et animation** : AmÃ©lioration des dialogues animÃ©s.  
- ğŸ§‘â€ğŸ’» **VisioconfÃ©rences** : Avatars interactifs qui rÃ©agissent naturellement.  

---

### ğŸ’¡ Pourquoi AuroraNet ?  
AuroraNet apporte une nouvelle dimension aux interactions homme-machine grÃ¢ce Ã  son approche innovante. Ce projet a pour ambition de repousser les limites de la technologie audio-visuelle !

### ğŸ“š RÃ©fÃ©rences  
Le dataset **VocazSet** utilisÃ© pour cette premiÃ¨re version d'AuroraNet est basÃ© sur l'article suivant :

```bibtex
@inproceedings{VOCA2019,
    title = {Capture, Learning, and Synthesis of {3D} Speaking Styles},
    author = {Cudeiro, Daniel and Bolkart, Timo and Laidlaw, Cassidy and Ranjan, Anurag and Black, Michael},
    booktitle = {Proceedings IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)},
    pages = {10101--10111},
    year = {2019},
    url = {http://voca.is.tue.mpg.de/}
}

VocazSet est un dataset utilisÃ© pour la capture et l'apprentissage des styles de parole en 3D. Il a Ã©tÃ© prÃ©sentÃ© dans l'article "Capture, Learning, and Synthesis of 3D Speaking Styles" (Cudeiro et al., 2019). Pour plus d'informations, vous pouvez consulter le site officiel du dataset ici.
